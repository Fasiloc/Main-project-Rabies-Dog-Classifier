{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31df46ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barking', 'Digging', 'Dropped Jaw & Tongue', 'Hyper Salivation', 'Incoordination', 'No Detection', 'Paralysis', 'Playing', 'Running', 'Seizure', 'Wagging Tail']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "dataset_path = os.listdir('D:/Deep_Learning/Dog_Rabies_Project/videos/train')\n",
    "label_types = os.listdir('D:/Deep_Learning/Dog_Rabies_Project/videos/train')\n",
    "print(label_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247f84b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       tag                                         video_name\n",
      "0  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n",
      "1  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n",
      "2  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n",
      "3  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n",
      "4  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n",
      "              tag                                         video_name\n",
      "438  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n",
      "439  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n",
      "440  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n",
      "441  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n",
      "442  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...\n"
     ]
    }
   ],
   "source": [
    "# Dataset Preperation\n",
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    "    all_rooms = os.listdir('D:/Deep_Learning/Dog_Rabies_Project/videos/train' + '/' + item)# Get all file names\n",
    "    \n",
    "    for room in all_rooms:# Add them to the list\n",
    "        rooms.append((item, str('D:/Deep_Learning/Dog_Rabies_Project/videos/train' + '/' + item) + '/' + room))\n",
    "\n",
    "# Build DataFrame\n",
    "train_df = pd.DataFrame(data=rooms, columns = ['tag','video_name'])   \n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e078d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.loc[:, ['video_name', 'tag']]\n",
    "df.to_csv('train1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c5f694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barking', 'Digging', 'Dropped Jaw & Tongue', 'Hyper Salivation', 'Incoordination', 'No Detection', 'Paralysis', 'Playing', 'Running', 'Seizure', 'Wagging Tail']\n",
      "Types of behaviour found 11\n",
      "       tag                                         video_name\n",
      "0  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n",
      "1  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n",
      "2  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n",
      "3  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n",
      "4  Barking  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n",
      "              tag                                         video_name\n",
      "146  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n",
      "147  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n",
      "148  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n",
      "149  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n",
      "150  Wagging Tail  D:/Deep_Learning/Dog_Rabies_Project/videos/tes...\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.listdir('D:/Deep_Learning/Dog_Rabies_Project/videos/test')\n",
    "print(dataset_path)\n",
    "\n",
    "room_types = os.listdir('D:/Deep_Learning/Dog_Rabies_Project/videos/test')\n",
    "print('Types of behaviour found',len(dataset_path))\n",
    "\n",
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    "    all_rooms = os.listdir('D:/Deep_Learning/Dog_Rabies_Project/videos/test' + '/' + item)# Get all file names\n",
    "    \n",
    "    for room in all_rooms:# Add them to the list\n",
    "        rooms.append((item, str('D:/Deep_Learning/Dog_Rabies_Project/videos/test' + '/' + item) + '/' + room))\n",
    "\n",
    "# Build DataFrame\n",
    "test_df = pd.DataFrame(data=rooms, columns = ['tag','video_name'])   \n",
    "print(test_df.head())\n",
    "print(test_df.tail())\n",
    "\n",
    "df = test_df.loc[:, ['video_name', 'tag']]\n",
    "df.to_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6146a544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 443\n",
      "Total videos for testing: 151\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>304</td>\n",
       "      <td>D:/Deep_Learning/Dog_Rabies_Project/videos/tra...</td>\n",
       "      <td>Playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>D:/Deep_Learning/Dog_Rabies_Project/videos/tra...</td>\n",
       "      <td>Digging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>368</td>\n",
       "      <td>D:/Deep_Learning/Dog_Rabies_Project/videos/tra...</td>\n",
       "      <td>Seizure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>211</td>\n",
       "      <td>D:/Deep_Learning/Dog_Rabies_Project/videos/tra...</td>\n",
       "      <td>Incoordination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>D:/Deep_Learning/Dog_Rabies_Project/videos/tra...</td>\n",
       "      <td>Incoordination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                         video_name  \\\n",
       "304         304  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...   \n",
       "44           44  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...   \n",
       "368         368  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...   \n",
       "211         211  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...   \n",
       "199         199  D:/Deep_Learning/Dog_Rabies_Project/videos/tra...   \n",
       "\n",
       "                tag  \n",
       "304         Playing  \n",
       "44          Digging  \n",
       "368         Seizure  \n",
       "211  Incoordination  \n",
       "199  Incoordination  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train1.csv')\n",
    "test_df = pd.read_csv('test1.csv')\n",
    "\n",
    "print(f'Total videos for training: {len(train_df)}')\n",
    "print(f'Total videos for testing: {len(test_df)}')\n",
    "\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ea3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1,0]]\n",
    "            frames.append(frame)\n",
    "            \n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cfa3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    pooling = 'avg',\n",
    "    input_shape = (IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    \n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "    \n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name='feature_extractor')\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab393ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barking', 'Digging', 'Dropped Jaw & Tongue', 'Hyper Salivation', 'Incoordination', 'No Detection', 'Paralysis', 'Playing', 'Running', 'Seizure', 'Wagging Tail']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 5],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10],\n",
       "       [10]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df['tag']))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels = train_df['tag'].values\n",
    "labels = label_processor(labels[..., None]).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3efc8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ad67ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df['video_name'].values.tolist()\n",
    "    \n",
    "    labels = df['tag'].values\n",
    "    \n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "    \n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype='bool')\n",
    "    frame_features =  np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype='float32')\n",
    "    \n",
    "    for idx, path in enumerate(video_paths):\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "        \n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH), dtype='bool')\n",
    "        temp_frame_features =  np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype='float32')\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1 # 1 = not masked, 0 = masked\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"train_labels in train set: {train_labels.shape}\")\n",
    "\n",
    "print(f\"test_labels in train set: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c163c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "EPOCHS = 100\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "#     filepath = \"./tmp/rabies_classifier\"\n",
    "#     checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "#         filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "    )\n",
    "\n",
    "#     seq_model.load_weights(filepath)\n",
    "#     _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "#     print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6b1dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model structure in json file\n",
    "model_json = sequence_model.to_json()\n",
    "with open('model2.json','w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8d53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save trained model weight in .h5 file\n",
    "sequence_model.save_weights('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "235b5a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ed2d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Video_play():   \n",
    "    cap = cv2.VideoCapture(test_video)\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file.\")\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            face_detector = cv2.CascadeClassifier('Dog_Cascade.xml')\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            num_faces = face_detector.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "            for (x, y, w, h) in num_faces:\n",
    "                if Rab > Nor:\n",
    "                    cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (0, 0, 255), 4)\n",
    "                    cv2.putText(frame, f\"Rabies\", (x+5, y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, \n",
    "                                cv2.LINE_4)\n",
    "                elif Nor > Rab:\n",
    "                    cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (0, 255, 0), 4)\n",
    "                    cv2.putText(frame, f\"Normal\", (x+5, y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2,\n",
    "                                cv2.LINE_4)\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 4)\n",
    "                    \n",
    "            cv2.imshow('Rabies Detection', frame)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28484d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: D:/Deep_Learning/Dog_Rabies_Project/videos/test/Paralysis/030.mp4\n",
      "1/1 [==============================] - 1s 682ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 684ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 667ms/step\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 1s 679ms/step\n",
      "1/1 [==============================] - 1s 680ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Details:\n",
      "  Paralysis: 96.31%\n",
      "  Incoordination:  2.21%\n",
      "  Dropped Jaw & Tongue:  0.99%\n",
      "  Barking:  0.49%\n",
      "  No Detection:  0.00%\n",
      "Since Features of Rabies are more dominating among the features shown, the Final Result can be assumed as RABIES.\n"
     ]
    }
   ],
   "source": [
    "Rabies = ['Paralysis','Dropped Jaw & Tongue','Hyper Salivation','Incoordination','Seizure',]\n",
    "Normal = ['Barking','Running','Playing','Wagging Tail','Digging']\n",
    "Rab = 0\n",
    "Nor = 0\n",
    "No_Detect = 0\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    global Rab\n",
    "    global Nor\n",
    "    global No_Detect\n",
    "    count = 0\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "    \n",
    "    print('Details:')\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        if count < len(Rabies):\n",
    "            if class_vocab[i] == 'No Detection':\n",
    "                No_Detect += 1\n",
    "            print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "            if class_vocab[i] in Rabies:\n",
    "                Rab += 1\n",
    "            else:\n",
    "                Nor += 1\n",
    "        count += 1\n",
    "    return frames\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video)\n",
    "\n",
    "if Rab > Nor:\n",
    "    print(f'Since Features of Rabies are more dominating among the features shown, the Final Result can be assumed as RABIES.')\n",
    "elif Nor > Rab:\n",
    "    print(f'Since Features of Normal are more dominating among the features shown, the Final Result can be assumed as NORMAL.')\n",
    "else:\n",
    "    print('No Dog Detected.')\n",
    "\n",
    "play_video = Video_play()\n",
    "# End of the Program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a39fb606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51ddf787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import time\n",
    "\n",
    "# def live_capture():\n",
    "#     capture_duration = 9 # The duration in seconds of the video captured.\n",
    "\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#     out = cv2.VideoWriter('output.mp4',fourcc, 25, (640,480))\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     while( int(time.time() - start_time) < capture_duration ):\n",
    "#         ret, frame = cap.read()\n",
    "#         if ret==True:\n",
    "#             out.write(frame)\n",
    "#             cv2.imshow('frame',frame)\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9328a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71990712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d30b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fa89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tkinter\n",
    "\n",
    "# def UploadAction(event=None):\n",
    "#     test_video = filedialog.askopenfilename()\n",
    "#     print('Selected:', test_video)\n",
    "\n",
    "# root = tk.Tk()\n",
    "# button = tk.Button(root, text='Upload', command=UploadAction)\n",
    "# button.pack()\n",
    "\n",
    "# root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
